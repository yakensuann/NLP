'''å¾®è°ƒbertæ¨¡å‹åšæƒ…æ„Ÿåˆ†ç±»ï¼ˆæ–‡æœ¬åˆ†ç±»ï¼‰'''
import torch
from datasets import load_dataset
dataset = load_dataset('imdb')#imdbæ˜¯å…³äºç”µå½±è¯„è®ºçš„æ•°æ®é›† åŒ…å«åä¸‡æ¡è¯„è®º
print(dataset)
'''æ ‡è®°åŒ–æ•°æ®ï¼Œä½¿ç”¨Transformersä¸­çš„BertTokenizerå¯¹æ•°æ®è¿›è¡Œæ ‡è®°'''
from transformers import BertTokenizer
#æ–‡æœ¬é•¿åº¦é»˜è®¤ï¼Œå¯è‡ªè¡Œè®¾ç½®
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',max_length=512)
#å°†æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥å¤„ç†çš„æ ¼å¼ï¼ŒåŒ…æ‹¬å¡«å……å’Œæˆªæ–­
def tokenize_function(examples):
    return tokenizer(examples['text'], padding='max_length', truncation=True)

tokenized_datasets = dataset.map(tokenize_function, batched=True)

'''åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†'''
#æŒ‰ç…§8ï¼š2æŠŠè®­ç»ƒé›†è¿›ä¸€æ­¥åˆ’åˆ†ä½è®­ç»ƒé›†å’Œæµ‹è¯•é›†
train_testvalid = tokenized_datasets["train"].train_test_split(test_size=0.1, seed=42)
train_dataset = train_testvalid['train']
valid_dataset = train_testvalid['test']
'''ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†åˆ›å»ºæ•°æ®åŠ è½½å™¨'''
from torch.utils.data import DataLoader
#è®­ç»ƒæ•°æ®éšæœºæ‰“ä¹±ï¼Œå¢åŠ æ¨¡å‹æ³›åŒ–èƒ½åŠ›
train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)
valid_dataloader = DataLoader(valid_dataset, batch_size=16, shuffle=False)

'''åŠ è½½é¢„è®­ç»ƒæ¨¡å‹'''
from transformers import BertForSequenceClassification, AdamW
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)


'''å®šä¹‰è®­ç»ƒå‡½æ•°'''
from transformers import Trainer, TrainingArguments
training_args = TrainingArguments(
    output_dir='./results',          # output directory
    num_train_epochs=3,              # total number of training epochs
    evaluation_strategy='epoch',     # evaluation strategy to adopt during training
    per_device_train_batch_size=1,  # batch size per device during training
    per_device_eval_batch_size=1,   # batch size for evaluation
    weight_decay=0.01,               # strength of weight decay
    learning_rate=2e-5,              # learning rate
)
trainer = Trainer(
    model=model,                         # the instantiated ğŸ¤— Transformers model to be traine
    args=training_args,                  # training arguments, defined above
    train_dataset=train_dataset,         # training dataset
    eval_dataset=valid_dataset,          # evaluation dataset

)
trainer.train()
torch.cuda.empty_cache()
